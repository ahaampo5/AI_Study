{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c44c93f",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c01b9",
   "metadata": {},
   "source": [
    "> ### mmdetection config에 대한 이해 (HTC-swin-S-cascade-mask-rcnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3629b",
   "metadata": {},
   "source": [
    "- Total Config를 이루는 참조 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_base_ = [\n",
    "    '../_base_/datasets/coco_instance.py',\n",
    "    '../_base_/schedules/schedule_1x.py', '../_base_/default_runtime.py'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ed1ba",
   "metadata": {},
   "source": [
    "- Model 설정\n",
    " - 2 stage model로 이루어진 Object Detection모델이므로 rpn_head와 roi_head를 설정해주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd76482",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dict(\n",
    "    # HTC로 모델을 구성\n",
    "    type='HybridTaskCascade',\n",
    "    pretrained=None,\n",
    "    \n",
    "    # 모델의 swin_transformer_s backbone\n",
    "    # 각 stage의 단계마다 output을 활용하여 모델 구성\n",
    "    backbone=dict(\n",
    "        type='SwinTransformer',\n",
    "        embed_dim=96,\n",
    "        depths=[2, 2, 18, 2],\n",
    "        num_heads=[3, 6, 12, 24],\n",
    "        window_size=7,\n",
    "        mlp_ratio=4.,\n",
    "        qkv_bias=True,\n",
    "        qk_scale=None,\n",
    "        drop_rate=0.,\n",
    "        attn_drop_rate=0.,\n",
    "        drop_path_rate=0.2,\n",
    "        ape=False,\n",
    "        patch_norm=True,\n",
    "        out_indices=(0, 1, 2, 3),\n",
    "        use_checkpoint=False),\n",
    "\n",
    "    # 작은 물체에 대한 탐색 능력을 올리기 위해 neck을 통해 raw feature를 활용\n",
    "    neck=dict(\n",
    "        type='FPN',\n",
    "        in_channels=[96, 192, 384, 768],\n",
    "        out_channels=256,\n",
    "        num_outs=5),\n",
    "    # anchor박스를 만들어 물체가 있을 곳을 제안\n",
    "    rpn_head=dict(\n",
    "        type='RPNHead',\n",
    "        in_channels=256,\n",
    "        feat_channels=256,\n",
    "        anchor_generator=dict(\n",
    "            type='AnchorGenerator',\n",
    "            scales=[8], # EDA를 통해 큰 물체가 많으면 값 더크게 작은 물체가 많으면 작게\n",
    "            ratios=[0.5, 1.0, 2.0],\n",
    "            strides=[4, 8, 16, 32, 64]),\n",
    "        bbox_coder=dict(\n",
    "            type='DeltaXYWHBBoxCoder',\n",
    "            target_means=[.0, .0, .0, .0],\n",
    "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
    "        loss_cls=dict(\n",
    "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
    "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),\n",
    "    # anchor박스를 통해 만들어진 결과를 통해 물체가 맞는지 확인\n",
    "    roi_head=dict(\n",
    "        type='HybridTaskCascadeRoIHead',\n",
    "        # segmentation 정보를 활용하여 물체인지 확인\n",
    "        semantic_roi_extractor=dict(\n",
    "            type='SingleRoIExtractor',\n",
    "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
    "            out_channels=256,\n",
    "            featmap_strides=[8]),\n",
    "        semantic_head=dict(\n",
    "            type='FusedSemanticHead',\n",
    "            num_ins=5,\n",
    "            fusion_level=1,\n",
    "            num_convs=4,\n",
    "            in_channels=256,\n",
    "            conv_out_channels=256,\n",
    "            num_classes=24,\n",
    "            ignore_label=255,\n",
    "            loss_weight=0.2),\n",
    "        interleaved=True,\n",
    "        mask_info_flow=True,\n",
    "        num_stages=3,\n",
    "        stage_loss_weights=[1, 0.5, 0.25],\n",
    "        # classification을 통해 물체를 확인\n",
    "        bbox_roi_extractor=dict(\n",
    "            type='SingleRoIExtractor',\n",
    "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
    "            out_channels=256,\n",
    "            featmap_strides=[4, 8, 16, 32]),\n",
    "        bbox_head=[\n",
    "            dict(\n",
    "                type='Shared2FCBBoxHead',\n",
    "                in_channels=256,\n",
    "                fc_out_channels=1024,\n",
    "                roi_feat_size=7,\n",
    "                num_classes=11,\n",
    "                bbox_coder=dict(\n",
    "                    type='DeltaXYWHBBoxCoder',\n",
    "                    target_means=[0., 0., 0., 0.],\n",
    "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
    "                reg_class_agnostic=True,\n",
    "                loss_cls=dict(\n",
    "                    type='CrossEntropyLoss',\n",
    "                    use_sigmoid=False,\n",
    "                    loss_weight=1.0),\n",
    "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
    "                               loss_weight=1.0)),\n",
    "            dict(\n",
    "                type='Shared2FCBBoxHead',\n",
    "                in_channels=256,\n",
    "                fc_out_channels=1024,\n",
    "                roi_feat_size=7,\n",
    "                num_classes=11,\n",
    "                bbox_coder=dict(\n",
    "                    type='DeltaXYWHBBoxCoder',\n",
    "                    target_means=[0., 0., 0., 0.],\n",
    "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
    "                reg_class_agnostic=True,\n",
    "                loss_cls=dict(\n",
    "                    type='CrossEntropyLoss',\n",
    "                    use_sigmoid=False,\n",
    "                    loss_weight=1.0),\n",
    "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
    "                               loss_weight=1.0)),\n",
    "            dict(\n",
    "                type='Shared2FCBBoxHead',\n",
    "                in_channels=256,\n",
    "                fc_out_channels=1024,\n",
    "                roi_feat_size=7,\n",
    "                num_classes=11,\n",
    "                bbox_coder=dict(\n",
    "                    type='DeltaXYWHBBoxCoder',\n",
    "                    target_means=[0., 0., 0., 0.],\n",
    "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
    "                reg_class_agnostic=True,\n",
    "                loss_cls=dict(\n",
    "                    type='CrossEntropyLoss',\n",
    "                    use_sigmoid=False,\n",
    "                    loss_weight=1.0),\n",
    "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
    "        ],\n",
    "        mask_roi_extractor=dict(\n",
    "            type='SingleRoIExtractor',\n",
    "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
    "            out_channels=256,\n",
    "            featmap_strides=[4, 8, 16, 32]),\n",
    "        mask_head=[\n",
    "            dict(\n",
    "                type='HTCMaskHead',\n",
    "                with_conv_res=False,\n",
    "                num_convs=4,\n",
    "                in_channels=256,\n",
    "                conv_out_channels=256,\n",
    "                num_classes=11,\n",
    "                loss_mask=dict(\n",
    "                    type='CrossEntropyLoss', use_mask=True, loss_weight=1.0)),\n",
    "            dict(\n",
    "                type='HTCMaskHead',\n",
    "                num_convs=4,\n",
    "                in_channels=256,\n",
    "                conv_out_channels=256,\n",
    "                num_classes=11,\n",
    "                loss_mask=dict(\n",
    "                    type='CrossEntropyLoss', use_mask=True, loss_weight=1.0)),\n",
    "            dict(\n",
    "                type='HTCMaskHead',\n",
    "                num_convs=4,\n",
    "                in_channels=256,\n",
    "                conv_out_channels=256,\n",
    "                num_classes=11,\n",
    "                loss_mask=dict(\n",
    "                    type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))\n",
    "        ]),\n",
    "    train_cfg=dict(\n",
    "        rpn=dict(\n",
    "            assigner=dict(\n",
    "                type='MaxIoUAssigner',\n",
    "                pos_iou_thr=0.7,\n",
    "                neg_iou_thr=0.3,\n",
    "                min_pos_iou=0.3,\n",
    "                ignore_iof_thr=-1),\n",
    "            sampler=dict(\n",
    "                type='RandomSampler',\n",
    "                num=256,\n",
    "                pos_fraction=0.5,\n",
    "                neg_pos_ub=-1,\n",
    "                add_gt_as_proposals=False),\n",
    "            allowed_border=0,\n",
    "            pos_weight=-1,\n",
    "            debug=False),\n",
    "        rpn_proposal=dict(\n",
    "            nms_pre=2000,\n",
    "            max_per_img=2000,\n",
    "            nms=dict(type='nms', iou_threshold=0.7),\n",
    "            min_bbox_size=0),\n",
    "        rcnn=[\n",
    "            dict(\n",
    "                assigner=dict(\n",
    "                    type='MaxIoUAssigner',\n",
    "                    pos_iou_thr=0.5,\n",
    "                    neg_iou_thr=0.5,\n",
    "                    min_pos_iou=0.5,\n",
    "                    ignore_iof_thr=-1),\n",
    "                sampler=dict(\n",
    "                    type='RandomSampler',\n",
    "                    num=512,\n",
    "                    pos_fraction=0.25,\n",
    "                    neg_pos_ub=-1,\n",
    "                    add_gt_as_proposals=True),\n",
    "                mask_size=28,\n",
    "                pos_weight=-1,\n",
    "                debug=False),\n",
    "            dict(\n",
    "                assigner=dict(\n",
    "                    type='MaxIoUAssigner',\n",
    "                    pos_iou_thr=0.6,\n",
    "                    neg_iou_thr=0.6,\n",
    "                    min_pos_iou=0.6,\n",
    "                    ignore_iof_thr=-1),\n",
    "                sampler=dict(\n",
    "                    type='RandomSampler',\n",
    "                    num=512,\n",
    "                    pos_fraction=0.25,\n",
    "                    neg_pos_ub=-1,\n",
    "                    add_gt_as_proposals=True),\n",
    "                mask_size=28,\n",
    "                pos_weight=-1,\n",
    "                debug=False),\n",
    "            dict(\n",
    "                assigner=dict(\n",
    "                    type='MaxIoUAssigner',\n",
    "                    pos_iou_thr=0.7,\n",
    "                    neg_iou_thr=0.7,\n",
    "                    min_pos_iou=0.7,\n",
    "                    ignore_iof_thr=-1),\n",
    "                sampler=dict(\n",
    "                    type='RandomSampler',\n",
    "                    num=512,\n",
    "                    pos_fraction=0.25,\n",
    "                    neg_pos_ub=-1,\n",
    "                    add_gt_as_proposals=True),\n",
    "                mask_size=28,\n",
    "                pos_weight=-1,\n",
    "                debug=False)\n",
    "        ]),\n",
    "    test_cfg=dict(\n",
    "        rpn=dict(\n",
    "            nms_pre=1000,\n",
    "            max_per_img=1000,\n",
    "            nms=dict(type='nms', iou_threshold=0.7),\n",
    "            min_bbox_size=0),\n",
    "        rcnn=dict(\n",
    "            score_thr=0.001,\n",
    "            nms=dict(type='nms', iou_threshold=0.5),\n",
    "            max_per_img=100,\n",
    "            mask_thr_binary=0.5)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0982ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "\n",
    "# augmentation\n",
    "albu_train_transforms = [\n",
    "    dict(\n",
    "        type='VerticalFlip',\n",
    "        p=0.5),\n",
    "    dict(\n",
    "        type='RandomBrightnessContrast',\n",
    "        brightness_limit=[-0.1, 0.1],\n",
    "        contrast_limit=[-0.1, 0.1],\n",
    "        p=0.7),\n",
    "    dict(\n",
    "        type='CLAHE',\n",
    "        clip_limit=2.0),\n",
    "    dict(\n",
    "        type='HueSaturationValue',\n",
    "        hue_shift_limit=10,\n",
    "        sat_shift_limit=15,\n",
    "        val_shift_limit=10),\n",
    "    dict(\n",
    "        type='RandomRotate90'),\n",
    "    dict(\n",
    "        type='OneOf',\n",
    "        transforms=[\n",
    "            dict(type='MedianBlur', blur_limit=5),\n",
    "            dict(type='MotionBlur', blur_limit=5),\n",
    "            dict(type='GaussianBlur', blur_limit=5),\n",
    "        ],\n",
    "        p=0.7),\n",
    "    dict(\n",
    "        type='GaussNoise', var_limit=(5.0, 30.0), p=0.5)\n",
    "]\n",
    "\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='InstaBoost',\n",
    "        action_candidate=('normal', 'horizontal', 'skip'),\n",
    "        action_prob=(1, 0, 0),\n",
    "        scale=(0.8, 1.2),\n",
    "        dx=15,\n",
    "        dy=15,\n",
    "        theta=(-1, 1),\n",
    "        color_prob=0.,\n",
    "        hflag=False,\n",
    "        aug_ratio=0.5),\n",
    "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True, with_seg=True),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='AutoAugment',\n",
    "         policies=[\n",
    "             [\n",
    "                 dict(type='Resize',\n",
    "                      img_scale=[(512, 512),(576, 576),(640, 640),(704, 704),(768, 768),\n",
    "                      (832, 832),(896, 896),(960, 960),(1024, 1024)],\n",
    "                      multiscale_mode='value',\n",
    "                      keep_ratio=True)\n",
    "             ],\n",
    "             [\n",
    "                 dict(type='Resize',\n",
    "                      img_scale=[(512, 512), (768, 768), (1024, 1024)],\n",
    "                      multiscale_mode='value',\n",
    "                      keep_ratio=True),\n",
    "                 dict(type='RandomCrop',\n",
    "                      crop_type='absolute_range',\n",
    "                      crop_size=(512, 512),\n",
    "                      allow_negative_crop=True),\n",
    "                 dict(type='Resize',\n",
    "                      img_scale=[(512, 512),(576, 576),(640, 640),(704, 704),(768, 768),\n",
    "                      (832, 832),(896, 896),(960, 960),(1024, 1024)],\n",
    "                      multiscale_mode='value',\n",
    "                      override=True,\n",
    "                      keep_ratio=True)\n",
    "             ]\n",
    "         ]),\n",
    "#     dict(type='Mixup'),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(\n",
    "        type='Albu',\n",
    "        transforms=albu_train_transforms,\n",
    "        bbox_params=dict(\n",
    "            type='BboxParams',\n",
    "            format='pascal_voc',\n",
    "            label_fields=['gt_labels'],\n",
    "            min_visibility=0.0,\n",
    "            filter_lost_elements=True),\n",
    "        keymap={\n",
    "            'img': 'image',\n",
    "            'gt_masks': 'masks',\n",
    "            'gt_bboxes': 'bboxes'\n",
    "        },\n",
    "        update_pad_shape=False,\n",
    "        skip_img_without_anno=True),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='SegRescale', scale_factor=1 / 8),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks', 'gt_semantic_seg']),\n",
    "]\n",
    "data = dict(train=dict(pipeline=train_pipeline))\n",
    "\n",
    "optimizer = dict(_delete_=True, type='AdamW', lr=0.0001, betas=(0.9, 0.999), weight_decay=0.05,\n",
    "                 paramwise_cfg=dict(custom_keys={'absolute_pos_embed': dict(decay_mult=0.),\n",
    "                                                 'relative_position_bias_table': dict(decay_mult=0.),\n",
    "                                                 'norm': dict(decay_mult=0.)}))\n",
    "lr_config = dict(step=[27, 33])\n",
    "runner = dict(type='EpochBasedRunnerAmp', max_epochs=60)\n",
    "\n",
    "# do not use mmdet version fp16\n",
    "fp16 = None\n",
    "optimizer_config = dict(\n",
    "    type=\"DistOptimizerHook\",\n",
    "    update_interval=1,\n",
    "    grad_clip=None,\n",
    "    coalesce=True,\n",
    "    bucket_size_mb=-1,\n",
    "    use_fp16=True,\n",
    ")\n",
    "\n",
    "load_from = \"/opt/ml/input/data/pth/cascade_mask_rcnn_swin_small_patch4_window7.pth\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
