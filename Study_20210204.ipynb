{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impossible-advantage",
   "metadata": {},
   "source": [
    "# **학업 일지**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-space",
   "metadata": {},
   "source": [
    "#### 오늘의 한마디  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-feedback",
   "metadata": {},
   "source": [
    "> **모델을 구현 할 때 목적이 뭔지 명확하게 정의하고 그 문제가 가지는 성향까지 정리를 해야한다. 어떤 성향을 가지느냐를 잘 분석하고 구현해야 좋은 모델이 만들어진다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-theorem",
   "metadata": {},
   "source": [
    "## 1. 강의 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-oklahoma",
   "metadata": {},
   "source": [
    "### 1.1 시퀀스 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-magic",
   "metadata": {},
   "source": [
    "#### 1.1.1 시퀀스 데이터의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-allen",
   "metadata": {},
   "source": [
    "- 소리, 문자열, 주가 등의 시퀀스가 있는 데이터  \n",
    "\n",
    "- 독립동등분포(i.i.d) 가정을 잘 위배하기 때문에 순서를 바꾸거나 과거 정보에 손실이 발생하면 확률분포도 바뀐다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-version",
   "metadata": {},
   "source": [
    "- 조건부 확률 분포  \n",
    "\n",
    "- 길이가 가변적인 데이터를 다룰 수 있는 모델이 필요하다.  \n",
    "그에 대한 대체로 타우개수만큼 예측한다. (Autoregressive Model)\n",
    "직전 정보와 그 이전 정보를 하나로 묶은 정보를 기준으로 예측한다. (\n",
    "과거정보를 어떻게 묶을까? 에 대한 해답이 RNN이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-appointment",
   "metadata": {},
   "source": [
    "#### 1.1.2 RNN의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-harvey",
   "metadata": {},
   "source": [
    "- RNN  \n",
    "![image.png](./img/rnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-portuguese",
   "metadata": {},
   "source": [
    "- BPTT  \n",
    "\n",
    "- truncated BPTT  \n",
    "gradient를 모두 곱해지는 형태이기 때문에 모든 t시점에서 학습하지 않고 적절한 시점에서 끊어주는 것이 중요하기 때문에 나온 방법 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-bruce",
   "metadata": {},
   "source": [
    "### 1.2 Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-polls",
   "metadata": {},
   "source": [
    "#### 1.2.1 Sequential Model 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-standing",
   "metadata": {},
   "source": [
    "- 이전 정보를 고려하는 것 : 정보량이 계속 늘어난다.  \n",
    "Fix the past timespan : 이전 정보의 양을 정해서 정해진 만큼만 본다.  \n",
    "Markov Model : 현재 판단의 기준은 바로 직전 정보만으로 가정한다.  \n",
    "Latent autoregressive model : Hidden state를 넣어서 여태까지의 과거를 요약한 요소를 넣어준다.  \n",
    "![image.png](./img/latent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-collins",
   "metadata": {},
   "source": [
    "#### 1.2.2 RNN의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-family",
   "metadata": {},
   "source": [
    "- RNN의 단점 (기본 RNN : Vanilla RNN) \n",
    "- short-term dependencies는 잘 잡지만 long-term dependencies는 취합하는 구조이기 때문에 잘 잡지 못한다.  \n",
    " - 예전 정보에 대해서 activation function을 많이 거치면서 grdient가 0보다 작으면 vanishing gradient문제가 생기고 1보다 큰 경우에는 exploding gradient 문제가 생긴다. \n",
    " - RNN에서 relu를 자주쓰지않는 이유가 된다.\n",
    "- RNN이 왜 어려운가  \n",
    "t가 진행될수록 hidden state가 매우 커지거나 매우작아지는 현상이 생긴다.  \n",
    " - 그에 대한 개선책으로 과거의 정보를 잘 취합하여 처리해주는 Long Short term memory(LSTM)의 개념이 시작되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-simon",
   "metadata": {},
   "source": [
    "#### 1.2.3 Long Short Term Memory(LSTM)  \n",
    "![image.png](./img/lstm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-force",
   "metadata": {},
   "source": [
    "- Forget gate, Input gate, Update cell, Output gate  \n",
    "![image.png](./img/gate1.png)\n",
    "![image.png](./img/gate2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-antibody",
   "metadata": {},
   "source": [
    "- Forget gate는 새로운 input과 전의 hidden을 mapping시킨 것(어떻게 매핑??)\n",
    "- Input gate는 input과 전의 hidden을 mapping시킨 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-treasury",
   "metadata": {},
   "source": [
    "#### 1.2.4 Gated Recurrent Unit(GRU)\n",
    "hidden state로만 학습을 시킨다. (파라미터를 줄이자.)  \n",
    "![image.png](./img/gru.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-miller",
   "metadata": {},
   "source": [
    "- 하지만 RNN구조가 transfrom으로 대체되고있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-confidentiality",
   "metadata": {},
   "source": [
    "### 1.3 Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-signature",
   "metadata": {},
   "source": [
    "#### 1.3.1 Transformer의 어려운 점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-coupon",
   "metadata": {},
   "source": [
    "- Data\n",
    " - Trimmed sequence : 잘리는 경우  \n",
    " - Omitted sequence : 생략되는 경우  \n",
    " - Permuted sequence : 순서가 섞이는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-afghanistan",
   "metadata": {},
   "source": [
    "- 기계어가 어떻게 sequential data를 처리하고 encoding할 수 있는가?\n",
    "sequence to sequence  \n",
    "입력 개수와 출력이 다를 수 있다. - 모델은 하나다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-radar",
   "metadata": {},
   "source": [
    "- 1. n개의 단어가 어떻게 한번에 처리되는가  \n",
    "\n",
    "> ![image.png](./img/tran_encoder.png)  \n",
    "> - Self-Attention 구조  \n",
    "  ` 단어가 들어오면 그에맞는 벡터를 찾아준다.(dictionary) - Self attention구조는 주변 모든 단어를 활용한다.> (한 단어가 여러 단어 사이에 어떤 관계가 있는지 학습한다.) - Q, K, V vector가 정해지면 q벡터를 자신을 포함한 각각의 k벡터와 내적하여 score 벡터를 만들어준다.(얼마나 q가 다른 k와 관련이 있는지 확인) - 크기를 k or q의 디멘션으로 나누어 줄여준다. - 확률적으로 표현하기 위해 Softmax함수로 표현한다. - softmax 결과로 나온 값을 value 벡터와 곱해준다. - 그리고 모든 합이 결과로 정해진다.`  \n",
    " q, k, v vector는 어떻게 만들어지나? k, q 벡터 차원은 달라도 되지만 실제 구현은 편의상 같게한다.\n",
    "![image.png](./img/trans_concept.png)\n",
    "> - Multi-headed attention (MHA)  \n",
    "n개의 q, k, v vector를 만들어주고 attention 구조를 지나온 n개의 결과를 입력과 출력의 매트릭스를 맞추기 위해 concatenate시키고 mapping을 시켜준다.  \n",
    "하지만 실제구현은 입력에 대해 n개를 다만들지 않고 입력을 n개로 나누어서 q, k, v vector를 만들고 합쳐준다.  \n",
    "> - Position encoding  \n",
    "\n",
    "\n",
    "- 2. 디코더 인코더 사이에 어떤 정보를 주고받는가  \n",
    "인코더는 디코더에게 key value를 보낸다.  \n",
    "\n",
    "- 3. 디코더가 어떻게 generation할수있는가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-guard",
   "metadata": {},
   "source": [
    "## 2. 피어 세션 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-fashion",
   "metadata": {},
   "source": [
    "#### 2.1 스터디"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-kruger",
   "metadata": {},
   "source": [
    "- 2.1.1 VGG 모델과 ResNet의 논문을 해석하고 실제 코드를 리뷰하였다.(발표: 이주남)\n",
    "\n",
    "- 2.1.2 신호처리의 입장에서 2-D Convolution에 대해 분석하였고 ResNet101과 FCN를 이용하여 Semantic Segmentation의 구현과 코드리뷰를 했다.(발표: 김준철)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-adult",
   "metadata": {},
   "source": [
    "#### 2.2 원하는 진로를 잡고 논문 공부"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-mattress",
   "metadata": {},
   "source": [
    "- Deep Learning : Yann LeCnn, Yoshua Bengio & Geoffrey Hinton\n",
    "딥러닝에 대한 전반적인 이해를 돕고 AI 논문에 대한 언어 장벽을 없애기 위해 필요하며 발표 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-finding",
   "metadata": {},
   "source": [
    "## 3. 진행중인 공부 및 신규 공부 목록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-violation",
   "metadata": {},
   "source": [
    "- 진행중인 공부  \n",
    "\n",
    "    - Deep learning 논문 읽고 정리하기\n",
    "    - AI 기본 수학 : Mathematics for Machine learning - Marc Peter Deisenroth 3과 공부\n",
    "    - 웹 크롤링 및 데이터 처리 연습 익숙해지기\n",
    "    - Numpy를 이용하여 프로젝트 하나 진행해보기 (wav파일로 악보를 추출하는 것을 계획중)\n",
    "    - Pandas 연산 반복 학습 하기\n",
    "    - Pytorch로 시작하는 딥러닝, Pytorch tutorial 공부  \n",
    "    - pytorch 데이터셋 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-payroll",
   "metadata": {},
   "source": [
    "- 신규 공부 목록  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-particular",
   "metadata": {},
   "source": [
    "- 완료한 공부  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-monkey",
   "metadata": {},
   "source": [
    "## 4. 감사한 일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-bridges",
   "metadata": {},
   "source": [
    "- 항상 좋은 질문으로 피어세션이 도움되게 해주는 팀원들에게 감사합니다.  \n",
    "- 난이도가 점점 어려워지면서 시간쏟는 것도 매우 많지만 밝은 모습으로 좋은 분위기를 만드는 팀원들에게 감사합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
