{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impossible-advantage",
   "metadata": {},
   "source": [
    "# **학업 일지**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-space",
   "metadata": {},
   "source": [
    "#### 오늘의 한마디  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-feedback",
   "metadata": {},
   "source": [
    "> **RNN에 Attention구조를 사용하여 NLP모델링의 다양한 구현을 해보자.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-theorem",
   "metadata": {},
   "source": [
    "## 1. 강의 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-oklahoma",
   "metadata": {},
   "source": [
    "### 1.1 Pre-Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-magic",
   "metadata": {},
   "source": [
    "#### 1.1.1 GPT-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-allen",
   "metadata": {},
   "source": [
    "- 특징 : 다양한 special token을 넣어 심플한 테스트, 많은 테스크를 동시에 처리할 수 있는 통합모델\n",
    "- start, text, extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-version",
   "metadata": {},
   "source": [
    "#### 1.1.2 Bert\n",
    "- dot product로 hidden간의 관계를 계산하는경우\n",
    "- general : 일반적인 매트릭스를 hidden vector 사이에 추가해 계산하는 경우\n",
    "- concat : hidden vector 두개를 concat시킨 후 neural net을 통하고 scalar값을 도출하기 위해 transpose 벡터를 내적해주는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-appointment",
   "metadata": {},
   "source": [
    "#### 1.1.3 장점과 특성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-portuguese",
   "metadata": {},
   "source": [
    "- Seq2seq 모델에 추가되면서 기계번역에서 성능을 많이 올려주었다.\n",
    "- 긴 문장에 대해 학습이 잘 되지 않는 문제를 해결했다.\n",
    "- 언제 어떤 단어를 봐야할지 뉴럴넷이 스스로 선택하는 구조를 만들어준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-flour",
   "metadata": {},
   "source": [
    "#### 1.1.4 GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-diary",
   "metadata": {},
   "source": [
    "- 모델자체는 gpt-1에 비해 다르지 않지만 많이 쌓았다.\n",
    "- 트레인 데이터 역시 많이 썼다. 그리고 추가적으로 높은 질의 문장을 사용하였다.\n",
    "- layer이 올라갈수록 parameter의 값을 작게 초기화하여 높은 layer일수록 적은 영향을 주도록 설계했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-horizontal",
   "metadata": {},
   "source": [
    "#### 1.1.5 GPT-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-colombia",
   "metadata": {},
   "source": [
    "- GPT-3 보다 비교할수없을만큼 많은 layer을 쌓고 많은 데이터, 높은 batch size로 학습시켜 나은 성능을 만들어냈다.  \n",
    "- zero shot, one shot, few shot setting에서 높은 성능을 보여주었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-civilian",
   "metadata": {},
   "source": [
    "#### 1.1.6 ALBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-policy",
   "metadata": {},
   "source": [
    "- 경량화 모델\n",
    "- factorized embeddingparameterization - embedding layer의 demension을 줄인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-vacuum",
   "metadata": {},
   "source": [
    "![Albert.png](./img/albert.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-corpus",
   "metadata": {},
   "source": [
    "#### 1.1.7 ELECTRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-building",
   "metadata": {},
   "source": [
    "- Generator, Discriminator 블록을 만들어 경쟁구조를 구성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-memorial",
   "metadata": {},
   "source": [
    "#### 1.1.8 Light-weight Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-convention",
   "metadata": {},
   "source": [
    "- 적은 cost로 모델을 만들어 활용성, 범용성을 높인다.\n",
    "- DistillBERT : teacher모델과 student모델로 이루어져 학습시킨다.\n",
    "- TinyBERT : DistillBERT + attention matrix,hidden matrix도 sudent가 닮도록 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-guard",
   "metadata": {},
   "source": [
    "## 2. 피어 세션 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-fashion",
   "metadata": {},
   "source": [
    "#### 2.1 스터디"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-kruger",
   "metadata": {},
   "source": [
    "- 2.1.1 Self attention 구조 코드구현 및 발표(발표: 이주남)\n",
    "\n",
    "- 2.1.2 Transformer의 encoder, decoder 코드 리뷰 (발표: 김준철)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-adult",
   "metadata": {},
   "source": [
    "#### 2.2 원하는 진로를 잡고 논문 공부"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-mattress",
   "metadata": {},
   "source": [
    "- 새로운 논문 선택 gpt-1 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-finding",
   "metadata": {},
   "source": [
    "## 3. 진행중인 공부 및 신규 공부 목록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-violation",
   "metadata": {},
   "source": [
    "- 진행중인 공부  \n",
    "\n",
    "    - AI 기본 수학 : Mathematics for Machine learning - Marc Peter Deisenroth 4과 공부\n",
    "    - 웹 크롤링 및 데이터 처리 연습 익숙해지기\n",
    "    - Pytorch로 시작하는 딥러닝, Pytorch tutorial 공부  \n",
    "    - pytorch 데이터셋 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-payroll",
   "metadata": {},
   "source": [
    "- 신규 공부 목록  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-particular",
   "metadata": {},
   "source": [
    "- 완료한 공부  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-monkey",
   "metadata": {},
   "source": [
    "## 4. 감사한 일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-bridges",
   "metadata": {},
   "source": [
    "- 정말 좋은 과제 내주시고 깊게 생각할 기회 준 문영기 조교님에게 감사합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
