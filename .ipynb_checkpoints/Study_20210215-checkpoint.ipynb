{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impossible-advantage",
   "metadata": {},
   "source": [
    "# **학업 일지**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-space",
   "metadata": {},
   "source": [
    "#### 오늘의 한마디  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-feedback",
   "metadata": {},
   "source": [
    "> **자연어 처리의 시작은 전처리다. embedding에 대해 다양한 방법론 이해하자.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-theorem",
   "metadata": {},
   "source": [
    "## 1. NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-oklahoma",
   "metadata": {},
   "source": [
    "### 1.1 NLP의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-magic",
   "metadata": {},
   "source": [
    "#### 1.1.1 NLP의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-allen",
   "metadata": {},
   "source": [
    "- NLP의 종류 : NLU(문장 이해), NLG(문장 생성)\n",
    "- NLP의 분야 : language modeling, machine translation, Q&A. codument classification\n",
    "- 학계 : ACL, EMNLP, NAACL\n",
    "- 용어 : token(단어), tokenizaion(단어쪼개기), 어근추출(stemming),\n",
    "- NER : 단일단어, 여러단어를 고유명사로 인식, POS : 품사나 특성을 알아내는 성분\n",
    "- Sentiment analysis : 감정분석, 긍정부정 분석 Machine translation :기계해석\n",
    "- Entailment prediction : 의미 추론, Question answering : 독해기반의 질의 응답 dialog systems : 챗봇, summarization : 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-version",
   "metadata": {},
   "source": [
    "#### text mining\n",
    "- 키워드 빈도수를 통해 트렌드 분석\n",
    "- 예시 : 소비자 반응\n",
    "- topic modeling, document clustering : 특징을 군집화\n",
    "- 사회 현상을 분석 : 사회과학적 통찰력을 얻기위해 활용\n",
    "- 학계 : KDD, The WebConf(formerly, WWW), WSDM, CIKM, ICWSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-situation",
   "metadata": {},
   "source": [
    "#### 정보 검색분야\n",
    "- 예시 : 추천 시스템 자동화, 능동적 정보 검색분야"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-france",
   "metadata": {},
   "source": [
    "#### 최근 발전과정\n",
    "- text to words -> word to vector(word embedding)\n",
    "- RNN(LSTM,GRU)에서 Transformer 모델로 대체되었다.\n",
    "- 자가주도학습 - 앞뒤문맥을 통해 중간 사라진 단어를 예측할 수 있다.  \n",
    "butt, gpt-2, gpt-3 : 범용 인공지능 기술"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-appointment",
   "metadata": {},
   "source": [
    "### 1.2 Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-portuguese",
   "metadata": {},
   "source": [
    "- one hot vector\n",
    "- 두 단어의 l2 norm = 루트2, 내적 = 0\n",
    "- bag = one hot vector들의 합\n",
    "- 단점 : 단어가 들어있지않으면 무조건 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-harmony",
   "metadata": {},
   "source": [
    "### 1.3 Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-headline",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-authority",
   "metadata": {},
   "source": [
    "## 2. Word2Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-flour",
   "metadata": {},
   "source": [
    "### 2.1. Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-diary",
   "metadata": {},
   "source": [
    "- 단어마다의 유사도를 딥러닝을 이용하여 vector로 표현한다.\n",
    "- 주변의 단어들을 통해 단어의 의미를 학습할 수 있다. -> 확률분포를 예측할 수 있다.\n",
    "- input/ output 쌍을 만들어준다.\n",
    "- embedding matrix : onehot vector에 해당하는 요소만 뽑아오는 것으로 해석가능  \n",
    "총 단어 개수만큼의 low vector와의 내적값이 마지막 출력으로 나온다.\n",
    "- 의미 관계가 linear하게 학습이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-horizontal",
   "metadata": {},
   "source": [
    "- Continuous Bag of words  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-morocco",
   "metadata": {},
   "source": [
    "### 2.2 Word2vector 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-trigger",
   "metadata": {},
   "source": [
    "- 기계 번역: 다른언어간의 같은 의미에 대해 알기 쉽다.\n",
    "- 감정 분석: 각 단어의 긍정 부정을 용이하게 파악\n",
    "- image captioning : 이미지를 자연어 형태로 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-literacy",
   "metadata": {},
   "source": [
    "### 2.2  GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-ethiopia",
   "metadata": {},
   "source": [
    "- 두 단어간의 확률은 사전에 계산하고 \n",
    "- 새로운 로스func을 사용했다.-중복계산을 줄여줄수있다.\n",
    "학습이 빈번하게 일어날수록 높은 학습률을 가지는 word to vector에 비해 안정적이고 적은 데이터에 잘 학습된다.\n",
    "- <a> https://nlp.stanford.edu/projects/glove </a> 사이트에 오픈소스와 데이터가 공개되어있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-oriental",
   "metadata": {},
   "source": [
    "![image.png](./img/glove.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-reunion",
   "metadata": {},
   "source": [
    "목적함수 = 각 입력 출력 단어쌍들에 대해서 한 위도우 내에서 얼마나 등장했는지를 사전에 계산을 하고 입력어들의 embedding, 출력어들의 embedding의 내적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-guard",
   "metadata": {},
   "source": [
    "## 2. 피어 세션 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-fashion",
   "metadata": {},
   "source": [
    "#### 2.1 스터디"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-kruger",
   "metadata": {},
   "source": [
    "- 2.1.1 GAN 논문발표(발표: 김상현)\n",
    "\n",
    "- 2.1.2 Transformer에 대해 전체 개념을 잡고 실제 코드를 보고 분석하는 시간을 가졌다. (발표: 배새봄)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-adult",
   "metadata": {},
   "source": [
    "#### 2.2 원하는 진로를 잡고 논문 공부"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-mattress",
   "metadata": {},
   "source": [
    "- Deep Learning : Yann LeCnn, Yoshua Bengio & Geoffrey Hinton\n",
    "딥러닝에 대한 전반적인 이해를 돕고 AI 논문에 대한 언어 장벽을 없애기 위해 필요하며 발표 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-finding",
   "metadata": {},
   "source": [
    "## 3. 진행중인 공부 및 신규 공부 목록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-violation",
   "metadata": {},
   "source": [
    "- 진행중인 공부  \n",
    "\n",
    "    - Deep learning 논문 읽고 정리하기\n",
    "    - AI 기본 수학 : Mathematics for Machine learning - Marc Peter Deisenroth 3과 공부\n",
    "    - 웹 크롤링 및 데이터 처리 연습 익숙해지기\n",
    "    - Pytorch로 시작하는 딥러닝, Pytorch tutorial 공부  \n",
    "    - pytorch 데이터셋 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-payroll",
   "metadata": {},
   "source": [
    "- 신규 공부 목록  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-particular",
   "metadata": {},
   "source": [
    "- 완료한 공부  \n",
    " - pandas, numpy 공부"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-monkey",
   "metadata": {},
   "source": [
    "## 4. 감사한 일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-bridges",
   "metadata": {},
   "source": [
    "- GAN에 대해 깊게 이해할 수 있도록 논문까지 정리해온 김상현 팀원에게 감사합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
