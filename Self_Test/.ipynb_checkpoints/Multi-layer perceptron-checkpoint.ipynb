{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "laden-waterproof",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch verison : [1.7.1]\n",
      "device : [cuda:0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "print(f'pytorch verison : [{torch.__version__}]')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device : [{device}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-beverage",
   "metadata": {},
   "source": [
    "- Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "empirical-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset = datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor(),download=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-greece",
   "metadata": {},
   "source": [
    "- Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quantitative-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "train_iter = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n",
    "test_iter = DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-control",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "developed-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,x_dim,h_dim,y_dim):\n",
    "        super(MLP,self).__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.lin_1 = nn.Linear(x_dim,h_dim)\n",
    "        self.lin_2 = nn.Linear(h_dim,y_dim)\n",
    "        self.init_param()\n",
    "        \n",
    "    def init_param(self):\n",
    "        nn.init.kaiming_normal_(self.lin_1.weight)\n",
    "        nn.init.zeros_(self.lin_1.bias)\n",
    "        nn.init.kaiming_normal_(self.lin_2.weight)\n",
    "        nn.init.zeros_(self.lin_2.bias)\n",
    "    \n",
    "    def forward(self,input):\n",
    "        x = input\n",
    "        x = self.lin_2(F.relu(self.lin_1(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "downtown-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(x_dim = 784, h_dim = 256, y_dim = 10).to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-dutch",
   "metadata": {},
   "source": [
    "- Model check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "prompt-perth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.44767374e-01 9.05907372e-01 4.65312950e-02 ... 7.31807971e-01\n",
      "  2.30314824e-01 1.33678027e-01]\n",
      " [4.56305096e-02 3.29474065e-02 3.22641576e-01 ... 8.46130974e-01\n",
      "  8.45394961e-01 8.25833215e-01]\n",
      " [7.57347473e-01 5.81760063e-01 6.53017126e-01 ... 6.58806099e-01\n",
      "  3.64242288e-01 1.75647079e-01]\n",
      " [5.12465196e-01 3.89134135e-01 8.72091231e-01 ... 6.96818152e-04\n",
      "  4.55809791e-01 8.41174974e-01]\n",
      " [5.53421054e-01 2.97467860e-01 2.42213845e-01 ... 5.11835320e-01\n",
      "  4.82667310e-01 3.28874053e-01]]\n",
      "tensor([[8.4477e-01, 9.0591e-01, 4.6531e-02,  ..., 7.3181e-01, 2.3031e-01,\n",
      "         1.3368e-01],\n",
      "        [4.5631e-02, 3.2947e-02, 3.2264e-01,  ..., 8.4613e-01, 8.4539e-01,\n",
      "         8.2583e-01],\n",
      "        [7.5735e-01, 5.8176e-01, 6.5302e-01,  ..., 6.5881e-01, 3.6424e-01,\n",
      "         1.7565e-01],\n",
      "        [5.1247e-01, 3.8913e-01, 8.7209e-01,  ..., 6.9682e-04, 4.5581e-01,\n",
      "         8.4117e-01],\n",
      "        [5.5342e-01, 2.9747e-01, 2.4221e-01,  ..., 5.1184e-01, 4.8267e-01,\n",
      "         3.2887e-01]], device='cuda:0')\n",
      "tensor([[ 2.1559,  0.7704, -0.1619,  0.0799,  0.4250, -0.0418,  0.1844, -0.0738,\n",
      "          1.0972, -0.4379],\n",
      "        [ 1.9423,  1.2273,  0.0793,  0.7822,  0.5538, -0.0738,  0.6756,  0.3373,\n",
      "          0.9104,  0.0265],\n",
      "        [ 1.8248,  0.0628, -0.0153,  0.2921, -0.5401, -0.0573,  0.8028,  0.1881,\n",
      "          0.1944, -0.3608],\n",
      "        [ 0.9249,  0.5513, -0.2447, -0.0825,  0.2633, -0.4599,  1.2734,  0.8877,\n",
      "          0.7815,  0.0225],\n",
      "        [ 1.9650,  0.5656, -0.0704,  0.1128,  0.7449,  0.0596,  1.1770,  0.5178,\n",
      "          1.1978, -0.2165]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "[[ 2.155877    0.7704021  -0.16194716  0.07992054  0.42503628 -0.04177141\n",
      "   0.18443541 -0.07379296  1.0971823  -0.43791214]\n",
      " [ 1.9423229   1.2272784   0.07930356  0.7821804   0.5537512  -0.07379156\n",
      "   0.67559767  0.33734637  0.9104106   0.02651393]\n",
      " [ 1.824825    0.06281576 -0.01525092  0.2920831  -0.54005456 -0.05730534\n",
      "   0.80279815  0.18806857  0.19440755 -0.36079237]\n",
      " [ 0.92491007  0.5512622  -0.24473381 -0.08247396  0.26332113 -0.45987663\n",
      "   1.2733827   0.8876686   0.7814878   0.02253091]\n",
      " [ 1.9649771   0.5655837  -0.07044095  0.11276095  0.74490225  0.05964637\n",
      "   1.176977    0.5177665   1.1977588  -0.21648517]]\n"
     ]
    }
   ],
   "source": [
    "x_numpy = np.random.rand(10,28*28)\n",
    "x_torch = torch.from_numpy(x_numpy).float().to(device)\n",
    "y_torch = model.forward(x_torch)\n",
    "y_numpy = y_torch.detach().cpu().numpy()\n",
    "print(x_numpy[:5])\n",
    "print(x_torch[:5])\n",
    "print(y_torch[:5])\n",
    "print(y_numpy[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-configuration",
   "metadata": {},
   "source": [
    "- Parameters check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "defined-chester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0], name : [lin_1.weight], parameters : [tensor([ 0.0182, -0.0592], device='cuda:0', grad_fn=<SliceBackward>)]\n",
      "[1], name : [lin_1.bias], parameters : [tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward>)]\n",
      "[2], name : [lin_2.weight], parameters : [tensor([ 0.0118, -0.1665], device='cuda:0', grad_fn=<SliceBackward>)]\n",
      "[3], name : [lin_2.bias], parameters : [tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward>)]\n",
      "parameters  203530\n"
     ]
    }
   ],
   "source": [
    "total_param = 0\n",
    "for i, (name,param) in enumerate(model.named_parameters()):\n",
    "    param_numpy = param.detach().cpu().numpy()\n",
    "    total_param += param_numpy.size\n",
    "    print(f'[{i}], name : [{name}], parameters : [{param.reshape(-1)[:2]}]')\n",
    "print('parameters ',total_param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
