{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surgical-lighting",
   "metadata": {},
   "source": [
    "# **학업 일지**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-sandwich",
   "metadata": {},
   "source": [
    "#### 오늘의 한마디  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-brain",
   "metadata": {},
   "source": [
    "> **경사하강법에 대한 기본이해를 바탕으로 코드를 작성할 수 있어야한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-camping",
   "metadata": {},
   "source": [
    "## 1. 강의 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-operations",
   "metadata": {},
   "source": [
    "#### *Numpy 연습을 통한 벡터와 행렬의 기본개념 숙지*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-medium",
   "metadata": {},
   "source": [
    "### 1.1 Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-taylor",
   "metadata": {},
   "source": [
    "#### 1.1.1 Sympy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-waters",
   "metadata": {},
   "source": [
    "- 미분 식 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foreign-light",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly(2*x + 2, x, domain='ZZ')\n"
     ]
    }
   ],
   "source": [
    "import sympy as sym\n",
    "from sympy.abc import x\n",
    "print(sym.diff(sym.poly(x**2 + 2*x + 3),x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-wilson",
   "metadata": {},
   "source": [
    "#### 1.1.2 Gradient Descent(GD) 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-commerce",
   "metadata": {},
   "source": [
    "- 데이터가 목표지점에 도달하기 위해서 회귀 계수를 갱신한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "monthly-disposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function: (2.00000000002418, Poly(x**2 + 2*x + 3, x, domain='ZZ')), cnt = 618, min = 2.00000000002418\n"
     ]
    }
   ],
   "source": [
    "import sympy as sym\n",
    "import numpy as np\n",
    "from sympy.abc import x\n",
    "\n",
    "def func(val):\n",
    "    \"\"\"\n",
    "    Initialize function\n",
    "    \"\"\"\n",
    "    fun = sym.poly(x**2 + 2*x + 3)\n",
    "    return fun.subs(x, val), fun\n",
    "\n",
    "def func_gradient(fun, val):\n",
    "    \"\"\"\n",
    "    Find a value of gradient\n",
    "    \"\"\"\n",
    "    _, function = fun(val)\n",
    "    diff = sym.diff(function, x)\n",
    "    return diff.subs(x, val), diff\n",
    "\n",
    "def gradient_descent(fun, init_point, lr_rate=1e-2, epsilon = 1e-5):\n",
    "    \"\"\"\n",
    "    Find minimum value of function by using GD\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    val = init_point\n",
    "    diff, _ = func_gradient(fun, init_point)\n",
    "    while np.abs(diff) > epsilon:\n",
    "        val = val - lr_rate*diff\n",
    "        diff, _ = func_gradient(fun, val)\n",
    "        cnt += 1\n",
    "    print(f'function: {fun(val)}, cnt = {cnt}, min = {fun(val)[0]}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gradient_descent(fun=func, init_point=np.random.uniform(-2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-score",
   "metadata": {},
   "source": [
    "선형대수(일차식의 집합연산)같은 경우에는 Pseudo-inverse matrix의 선형회귀를 통해 최적화 할 수 있지만 일반적인 식인 경우에는 구하기 어렵기 때문에 SGD를 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-consent",
   "metadata": {},
   "source": [
    "#### 1.1.3 GD with partial defferentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-wound",
   "metadata": {},
   "source": [
    "- 데이터가 목표지점에 가까워지도록 선형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "explicit-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무엇이 정답과 다른지 분석해보자\n",
    "import sympy as sym\n",
    "import numpy as np\n",
    "from sympy.abc import x, y\n",
    "\n",
    "def eval(fun, val):\n",
    "    val_x, val_y = val\n",
    "    fun_eval = fun.subs(x, val_x).subs(y, val_y)\n",
    "    return fun_eval\n",
    "    \n",
    "def func(val):\n",
    "    x_val, y_val = val\n",
    "    fun = sym.poly(x**2 + 2*y**2 + 5*x*y)\n",
    "    return eval(fun, val), fun\n",
    "\n",
    "def gradient(fun, val):\n",
    "    x_val, y_val = val\n",
    "    _, fun = fun(val)\n",
    "    diff_x = sym.diff(fun, x)\n",
    "    diff_y = sym.diff(fun, y)\n",
    "    grad_vec = np.array([eval(diff_x, [x_val,y_val]),eval(diff_y, [x_val, y_val])],dtype=float)\n",
    "    return grad_vec\n",
    "\n",
    "def gradient_descent(fun, init, lr=1e-2, epsilon=1e-5):\n",
    "    cnt = 0\n",
    "    val = init\n",
    "    _, fun = fun(val)\n",
    "    diff, _ = gradient(fun, val)\n",
    "    while np.linalg.norm(diff) > epsilon:\n",
    "        val = val - lr * diff\n",
    "        diff = gradient(fun, init_val)\n",
    "        cnt += 1\n",
    "                                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "patent-functionality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function: Poly(x**2 + 2*y**2, x, y, domain='ZZ'), cnt: 460, min: 2.49952603754474E-9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sym\n",
    "from sympy.abc import x, y\n",
    "\n",
    "def eval_(fun, val):\n",
    "    val_x, val_y = val\n",
    "    fun_eval = fun.subs(x, val_x).subs(y, val_y)\n",
    "    return fun_eval\n",
    "\n",
    "def func_multi(val):\n",
    "    x_, y_ = val\n",
    "    func = sym.poly(x**2 + 2*y**2)\n",
    "    return eval_(func, [x_,y_]), func\n",
    "\n",
    "def func_gradient(fun, val):\n",
    "    x_, y_ = val\n",
    "    _, function = fun(val)\n",
    "    diff_x = sym.diff(function, x)\n",
    "    diff_y = sym.diff(function, y)\n",
    "    grad_vec = np.array([eval_(diff_x, [x_,y_]), eval_(diff_y, [x_, y_])], dtype=float)\n",
    "    return grad_vec, [diff_x, diff_y]\n",
    "\n",
    "def gradient_descent(fun, init_point, lr=1e-2, epsilon=1e-4):\n",
    "    cnt=0\n",
    "    val =init_point\n",
    "    diff, _ = func_gradient(fun,val)\n",
    "    while (np.linalg.norm(diff) > epsilon):\n",
    "        val = val - lr*diff\n",
    "        diff, _ = func_gradient(fun, val)\n",
    "        cnt += 1\n",
    "    \n",
    "    print(f'function: {fun(val)[1]}, cnt: {cnt}, min: {fun(val)[0]}')\n",
    "\n",
    "gradient_descent(fun=func_multi,init_point=[np.random.uniform(-2,2), np.random.uniform(-2,2)])\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-sending",
   "metadata": {},
   "source": [
    "#### 1.1.4 벡터에서의 경사하강법을 이용한 선형회귀 알고리즘\n",
    "- 역행렬을 구하지 않고 회귀계수를 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sunset-press",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1 -1]\n",
      " [ 1  2 -1]\n",
      " [ 2  2 -1]\n",
      " [ 2  3 -1]]\n",
      "[-28.7 -41.8 -50.9 -64. ] [ 300.3  406.1 -185.4] [ 7.097 11.039 -4.646]\n",
      "[-0.01134889 -0.01550333  0.01070553  0.0065511 ] [-0.00766103  0.0012912  -0.0095956 ] [ 0.97386775  2.00414152 -0.03330736]\n",
      "[-0.00064241 -0.00084632  0.00057735  0.00037343] [-4.12832426e-04  6.00600768e-05 -5.37948298e-04] [ 9.98580455e-01  2.00020332e+00 -1.85678072e-03]\n",
      "[-3.56327344e-05 -4.65812990e-05  3.16921433e-05  2.07435787e-05] [-2.26574107e-05  3.18030954e-06 -2.97783114e-05] [ 9.99921953e-01  2.00001092e+00 -1.02659829e-04]\n",
      "[-1.96799189e-06 -2.56839222e-06  1.74642342e-06  1.14602310e-06] [-1.24850892e-06  1.73860195e-07 -1.64393759e-06] [ 9.99995698e-01  2.00000060e+00 -5.66596783e-06]\n",
      "[3 5 6 8]\n",
      "[[ 1  1 -1]\n",
      " [ 1  2 -1]\n",
      " [ 2  2 -1]\n",
      " [ 2  3 -1]]\n",
      "[ 9.99999762e-01  2.00000003e+00 -3.13502468e-07]\n",
      "[3.00000011 5.00000014 5.9999999  7.99999994]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,1],[1,2],[2,2],[2,3]])\n",
    "y = np.array(np.dot(x, np.array([1,2])))\n",
    "\n",
    "beta_gd = [10.1, 15.1, -6.5]\n",
    "x_ = np.array([np.append(i,[-1]) for i in x])\n",
    "print(x_)\n",
    "for t in range(5000):\n",
    "    error = y - x_ @ beta_gd\n",
    "    grad = - np.transpose(x_) @ error\n",
    "    beta_gd = beta_gd - 0.01 * grad\n",
    "    if t % 1000 == 0:\n",
    "        print(error, grad, beta_gd)\n",
    "\n",
    "print(y)\n",
    "print(x_)\n",
    "print(beta_gd)\n",
    "print(x_ @ beta_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-holiday",
   "metadata": {},
   "source": [
    "#### 1.1.5 Mini batch GD 직접 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-thermal",
   "metadata": {},
   "source": [
    "![sgd.png](./img/sgd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ceramic-mathematics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000145]\n",
      " [1.99999976]\n",
      " [2.9999981 ]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "x = np.array([[1,1],[1,2],[2,2],[2,3]]) # (4,2)\n",
    "y = np.array(np.dot(x, np.array([1,2]).T)) + 3 # (4,)\n",
    "beta_gd = np.array([10.1, 15.1, -6.5])[np.newaxis,:].T # (3,1)\n",
    "y = y[:,np.newaxis] # (4,1)\n",
    "lr = 0.01\n",
    "eps = 0.005\n",
    "x_ = np.array([np.append(i,[1]) for i in x]) # (4,3)\n",
    "mini_x = []\n",
    "mini_y = []\n",
    "batch = 2\n",
    "for i in range(len(x_)//batch):\n",
    "    mini_x.append(x_[i*batch:(i+1)*batch])\n",
    "    mini_y.append(y[i*batch:(i+1)*batch])\n",
    "for i in range(10000):\n",
    "    divide_standard = 1\n",
    "#     print(mini_x, mini_y)\n",
    "    if i%2 == 0:\n",
    "        divide_standard = 0\n",
    "    test_x = mini_x[divide_standard] # (2,3)\n",
    "    test_y = mini_y[divide_standard] # (2,1)\n",
    "#     print('test',test_x,test_y, beta_gd, test_x.shape)\n",
    "    y_ = test_x.dot(beta_gd)\n",
    "#     print('??',y_)\n",
    "    error = test_y - y_ # (2,1)\n",
    "#     print('error',error,error.shape)\n",
    "    beta_gd = beta_gd + 2/batch*lr*(test_x.T).dot(error)\n",
    "\n",
    "print(beta_gd)\n",
    "# label이 결정되면 그 모양을 만드는 batch만 만들수있네 이 경우에는 입력이 한 개 \n",
    "# 출력이 한개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "pursuant-location",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 5.99999931],\n",
       "        [ 7.99999907],\n",
       "        [ 9.00000053],\n",
       "        [11.00000028]]),\n",
       " array([[ 6],\n",
       "        [ 8],\n",
       "        [ 9],\n",
       "        [11]]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_@beta_gd, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-denial",
   "metadata": {},
   "source": [
    "수렴에 더 오래걸리지만 답에 근사하는 것을 볼 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-rouge",
   "metadata": {},
   "source": [
    "## 2. 피어 세션 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-series",
   "metadata": {},
   "source": [
    "#### 2.1 스터디"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-anderson",
   "metadata": {},
   "source": [
    "- 2.1.1 Numpy의 기본 활용 정리와 실제로 쓰일 수 있는 함수에 대해 리뷰하는 시간을 가졌다.(발표: 변재경)\n",
    "np.newaxis의 활용\n",
    "\n",
    "- 2.1.2 행렬에 대한 깊은 이해와 수학적 표현에 대해 토론하는 시간을 가졌다.(발표: 김상현)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-clinic",
   "metadata": {},
   "source": [
    "#### 2.2 원하는 진로를 잡고 논문 공부"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-france",
   "metadata": {},
   "source": [
    "- Deep Learning : Yann LeCnn, Yoshua Bengio & Geoffrey Hinton\n",
    "딥러닝에 대한 전반적인 이해를 돕고 AI 논문에 대한 언어 장벽을 없애기 위해 필요하며 발표 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-highland",
   "metadata": {},
   "source": [
    "## 3. 진행중인 공부 및 신규 공부 목록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-welcome",
   "metadata": {},
   "source": [
    "- 진행중인 공부  \n",
    "\n",
    "    - Deep learning 논문 읽고 정리하기\n",
    "    - AI 기본 수학 : Mathematics for Machine learning - Marc Peter Deisenroth\n",
    "    - 파이썬 파일관리를 기본으로 해서 프로젝트 하나 진행해보기\n",
    "    - 웹 크롤링 및 데이터 처리 연습 익숙해지기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-supplement",
   "metadata": {},
   "source": [
    "- 신규 공부 목록  \n",
    " \n",
    " - Numpy를 이용하여 프로젝트 하나 진행해보기 (파일 관리를 기본으로 한 프로젝트와 통합)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-fighter",
   "metadata": {},
   "source": [
    "- 완료한 공부  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-steps",
   "metadata": {},
   "source": [
    "## 4. 감사한 일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-fault",
   "metadata": {},
   "source": [
    "- 항상 질문을 많이하는데 친절하게 대답해주는 우리 팀에게 감사합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
